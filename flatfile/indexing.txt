=============================================

Open-bio flat-file indexing systems

At the recent O'Reilly Bioinformatics conferences (Tuscon, 2002), the
open-bio organizations decided to implement two flat-file indexing
systems, which can be used by all of the supported platforms,
including Biopython, Bioperl, BioJava, and BioRuby.  The goal of the
project is to retrieve flat-file records from a set of files given an
identifier.

Use case:

Sally, a bioinformatics researcher, needs fast access to many
different records from GenBank.  She is in a small group with little
experience in database management systems so wants a simple system
that doesn't involve a client/server model.  She also wants the
different tools she has (written for the different Bio* projects) to
be able to access the system, so she doesn't need to continuously
extract data with one tool for use by another.

[Insert more use cases?  What about one which lists the available
keys?]

The data in a set of files can be indexed in many ways.  It is
impossible to standarize the details of how that is done.  However,
the results of the indexing are consistent and can be shared across
the different platforms.

We call the collection of indexed files a "databank", to distinguish
it from a database which is usually closely associated with a database
management system like MySQL and PostgreSQL.  The databank has a whole
has a name, which is the "dbname".  The dbname consists of one or more
characters in the ranges "A-Z", "a-z", or "_".  The use of "_" as the
first character is discouraged.

NOTE: All variable names, identifiers, and other text are
case-sensitive.  An indexer may decide to normalize the input to a
given case, but normalization of a query must not be done by tools
which retrieve records from the index.  It is allowed for users of
those tools to provide an additional layer which does normalization,
but the lowest level access must provide case sensitive retrieval.


We decided on a simple relational data model for the information in
the databank.  Core to the system is a mapping from a unique primary
identifier name to the record location in a file.  The primary
identifier may derive from the contents of the record (eg, it is the
"entry_name" of a SWISS-PROT record) or may be an arbitrary unique
string generated by the indexer.  This last option is allowed for
certain formats which contain no unique identifer name.  In that case,
the identifier name should be based on the position of the record in
the file.

Because of the wide variety of names, the identifier name is one or
more characters from ASCII 32 (SPACE) to ASCII 126 (TILDE).  These are
the ASCII visible characters and is a proper subset of Unicode in the
UTF-8 encoding.  The use of a space is highly discouraged.

The content of a record is uniquely determined by the triple
   (filename, start position, length)

Together these are known as the location.  The "start position" is the
byte offset from the beginning of the file, where the first byte has
an offset of zero.  This must be the location of the file in C's
"binary" mode, which is unaffected by conversion of newline
conventions.  (Under Windows in text mode, the newline representation
of "\r\n" is converted to the single character "\n", so the character
location is different than the byte location.)

We chose to store "length" over "end position" because its string
representation is smaller.  The length is needed for a few formats
where the end of the record is not the same as the start of the next
record.  It is also needed for persistent storage mechanisms which
store the record keys infomation in unsorted order.

NOTE: the start location may be a integer greater than 2**32, which
cannot be expressed with a 32-bit integer.  According to the C
specification, the start location is of type "fpos_t" which on
non-UNIX systems may be an opaque, complex object.  Luckily, on modern
machines this simply mean that that position is available as an
integer with more than 32 bits.


The filename is a string appropriate to the local file system.  It
must only contain printable ASCII characters.  This is a recognized
limitation for portability of the index in that it may not be usable
across different filesystem (although I believe Mac, Unix and Windows
all now accept "/" as a directory separator).

NOTE: the filename may be a relative filename.  This must be allowed,
but it is discouraged because the current working directory for index
generation may be different than the current working directory for
programs using the index.  The failure behaviour when these two differ
is undefined.

Many records will have the same filename in the location.  To save
space and to allow easy relocation of files, this data is normalized
using a table called "fileids".  There is a one-to-one mapping between
filename and fileid, so the fileid is used in the location in lieu of
the filename.  The fileid is a unique nonnegative integer starting
from 0.  Gaps are not allowed, so the fileid sequence is 0, 1, 2, ....


Records may have multiple secondary identifiers.  There are different
types of secondary identifiers, like "accession", "author", and
"organism."  It is possible that the same word is used by more than
one identifier type, so we need the idea of a namespace, which allows
that disambiguation.  (NOTE: some systems may provide to ability to
find all uses of a given name in all namespaces.  That is outside the
scope of this specification.)

The indexing system supports this through an indirect lookup, first to
map from (namespace, identifier) to a list of 0 or more unique
identifiers, and second to retrieve the list of records given those
identifiers.

The identifier type is a string of the form "1 or more characters in
the ASCII range A-Z, a-z, or '_'."  This is equivalent to Perl's "\w+"
regular expression pattern when in the C locale.  It was chosen
because those strings may also be used as variable names in the major
languages.  NOTE: The use of "_" as the leading character is strongly
discouraged.

The unique identifier is in its own namespace.  While not needed for
primary identifier lookups, it is needed for consistency, since people
expect that a lookup by primary key and lookup by secondary key should
act the same.  If no primary namespace is appropriate, the indexer
should use the name "UNIQUE".

The actual names of the namespaces are determined by the indexing
system and outside the scope of this document.  They may come from the
format specification or from the person who runs the indexer.


   IMPLEMENTATIONS

We decided on two implementations, a flat-file only solution and one
built on Sleepycat's BerkeleyDB.

The first solution uses a set of text files, sorted so entry
information can be found by a binary search.  There are no existing
packages for the proposed file format, but from experience we believe
it is easy to support amoung the different projects.

The flat index files take up a lot of space and are hard to edit, and
there are faster lookups than a binary search.  For more complicated
uses, we decided to support BerkeleyDB from Sleepycat.  It is a widely
used DBM-style embedded database.  It runs as a set of libraries and
does not need a server.  It is portable across C, C++, Perl, Python,
and Java, although some have reported difficulties using it from Java.
(NOTE: we need someone from BioJava to try this out again.)

The biggest limitation in BerkeleyDB is the additional dependency of
an external library.  We want this system to work on a minimal Bio*
installation and still allow people do to work, which is why we have
two solutions.  They share the same data model and many of the same
text representations so it should be easy to support both
implementations.

 Flat-file implementation

The flat-file only solution is a simple indexing scheme based on
binary-searches of a file.

NOTE: In the following, the word "newline character" means the ASCII
character 10 (which is NEWLINE or "\n").  This character is used
independent of the operating system newline convention.  Software
which uses the index must read and write the files in binary mode so
there is no possibility of automatic newline character conversion.
The string "\n" is used to represent the newline character.

The data model is turned into a flat-file using the following
mechanism.

1) The data for the databank "dbname" is stored in the subdirectory of
the same name.

2) The subdirectory contains a file named "config.dat" containing tab
separated key/value pairs.  In this document, the tab character is
represented as the string "\t".  Each line will contain at least one
tab (the value may contain additional tabs).  Other than tab and the
terminal newline character, the line will only contain ASCII visible
characters.  All keys are unique.

3) The first line of config.dat contains the key "index" and value
"flat/1".  This means the first few characters of the config.dat file
is "index\tflat/1\n".  This allows implementations to determine the
indexing mechanism (eg, flat-file vs. BerkleyDB) automaticall and with
minimal work, and also allows future expansion.

4) The format of the flat files being indexed is stored in config.dat
under the key named "format".  The format is used to select the
correct parser for the flat files, and is one of:

	ace
	bsml
	embl
	fasta
	fastq
	game
	gcg
	genbank
	phd
	pir
	qual
	raw
	scf
	swiss

For example:

    "format" "\t" "embl" "\n"

5) The primary identifier namespace is stored in config.dat under the
key named 'primary_namespace'.  For example, if the dbname is
"swissprot" which uses the "ID" as the primary identifier then the
file "swissprot/config.dat" will contain the following line somewhere
in the file:

 "primary_namespace" "\t" "ID" "\n"

6) The "fileids" normalization table is stored in config.dat using
keys with a prefix of "fileid_" followed by the fileid number
represented as a text string, so legal keys include "fileid_0",
"fileid_1", and "fileid_314".  The keys are not zero filled, so
"fileid_00" is not an allowed key.  It is suggested that config.dat be
written so these entries are in successive order.

There are two terms in the fileid's value: the filename and the file
size.  They are stored as two tab separated fields, so the fileid
entries in the config.dat file are in the following form:

       <fileid> "\t" <filename> "\t" <file length> "\n"

For example, the following (between the quotes) is an allowed fileid
entry.

       "fileid_3\t/usr/local/datafiles/swiss1\t8675301\n"

By definition, the fileid and filename strings are not permitted to
contain ASCII control characters so no character escape machanism is
needed for the two terms.  If you use a filename with non-printable
characters, you get what you deserve.  :)

XXX Should the fileid entries include format name and alphabet
information?  Which format name?  Which alphabet encoding names?  If
so, who specifies them?

The file length is used as a simple check that the file has not
changed since it was indexed.  It is the total number of bytes in the
file, represented as a string.  The indexer is required to put the
proper value in this spot.  Users of the index should compare the file
sizes on the first attempt to access the file and report any
differences.

7) The list of secondary namespaces is stored in config.dat under the
key "secondary_namespaces".  Mutiple terms are separated by a tab
character.  If there are no secondary namespaces then this entry must
exist but the value is the empty string.

NOTE: In theory this data can be reconstructed by analysis of the file
system, but keeping the list here is simpler.

8) The mapping from primary identifier to location is stored in the
file "${dbname}/key_${UNIQUE}.key" where ${UNIQUE} is the primary
identifier namespace.  For example, if the dbname is "swissprot" and
the primary namespace is named "ID" then the filename is
"swissprot/key_ID.key".

Each record of this file is in a fixed width format.  There is no
special termination character.  Instead, the first four bytes of the
file contain the mapping record size, in bytes, represented as text
string.  The string is left padded with zeros to fit in four bytes, so
the allowed text strings are "0000", "0001", "0002", ..., "9999".

Suppose the mapping record size is 10, then the first record starts at
the fifth byte position and continues for ten characters.  In general,
if the mapping record size is N then record 'i' is found by

  seek(N*i+4)
  read(N)

The fixed width mapping record size makes it quick to scan with a
binary search.  From our experience, identifier names have little
variation in length so the extra space needed for fixed width is not
high, and the excess is mitigated somewhat by the lack of newline.

The four character value limits the largest mapping record size to
9999 characters.  If there is need for larger records then we will
define a new specification.  (NOTE: the size limitation is on the
mapping record, and not on the actual record being indexed.)

Records in the ".key" format are in the format

   <identifier> "\t" <fileid> "\t" <start position> \t <length> <padding>

The padding is done with zero or more space characters (ASCII 32 =
SPC) to fit to the record size.  The padding and field width is
determined by the indexer and outside the scope of this document,
except for the obvious requirement that the field width be enough to
store all data.

The identifier and fileid terms by definition cannot contain ASCII
control characters so there are no in-band problems.  The start
position and length are numbers stored as text strings, not as a
binary representation.  This increases portability at the expense of
some small amount of extra space.

The records in a .key file are sorted as characters in the C locale,
which means they are sorted in ASCII order.  Recall that by
construction the identifier names are unique so sorting on the
identifier name is sufficient to define a unique sorting.  Because
"\t" is the delimiter, the comparison of two identifiers is the same
as comparison as two records.  In other words, compare("A", "AB") ==
compare("A\t", "AB\t").  This allows for a fast comparisons of records
without breaking the record down into parts.

For example, for a SWISS-PROT record indexed by the "ID" field the
"swissprot/key_ID.key" file may start with the following text

0020100K_RAT\t0\t4495     104K_THEPA\t4495\t2816


9) The mappings from secondary namepaces to primary key are stored in
files of the form "${dbname}/id_${NAMESPACE}.index".  For example, if
there is a namespace called "accession" which maps accession names to
the primary identifier then there is a file named
"swissprot/id_accession.index".  Because of the restriction on
namespace names, there is no possibility of using a filesystem
specific character on any of the supported platforms.  (Eg, the
NAMESPACE word cannot contain the '/', '.', or ":" characters.)

Each record of the .key file is in a fixed width format.  Like in the
.key file, the record length is stored in the first four bytes as a
zero-padded text string and the first record record starts at the
fifth byte.

Each record contain fields; the secondary identifier then the primary
identifier.  These fields are tab separated and in the following
format

  <secondary identifier> "\t" <primary identifier>

The text is space padded on the right to fit into the record size.
Neither the name nor the primary identifier name contain ASCII control
chracters so there are no in-band concerns.

Records are sorted by the secondary identifier so that they may be
found by a binary search.  There may be more than one record with the
same identifier because the secondary identifier may map to one or
more primary identifier.  The method used to sort records with the
same secondary identifier is left up to the program which made the
index.

XXX Should the secondary sort key be the primary identifier?  I don't
see a good need for this extra work.  My code simply adds new terms on
the end, to preserve that retrieval order stays the same as input
order.

For example, the accession index for SWISS-PROT may start with the following


0019P02813\tPRP4_HUMAN  P02813\tPRPL_HUMAN  P02813\tPRPM_HUMAN  

(note: the above line ends with two spaces.)

This indicates that the accession "P02813" exists in the records
PRP4_HUMAN, PRPL_HUMAN, and PRPM_HUMAN.


NOTE: The .key filename starts with "key_" and the .index files start
with "id_" even though the suffix is sufficient to distinguish the two
files.  This is due to security concerns.  The namespace names come
from user input and an insecure implementation may not fully validate
that the input is limited to the allowed character set so may contain
".", "/" and the NUL (ASCII 0) characters.  This specification
requires that the indexing directory does not subdirectories with a
name starting with "id_" and "key_" so illegal namespaces cannot be
used to traverse the filesystem and perhaps leaking internal data.


    BerkeleyDB implementation

A BerkeleyDB database is a key/value table, which is a natural mapping
for the key/value information needed above.  A BerkeleyDB environment
can store multiple logical databases together.

The data model is turned into a BerkeleyDB using the following
mechanism:

NOTE: C and C++ implementations of BerkeleyDB must not append the
ASCII NUL character (with value 0).  This is occasionally done in
DBM-style databases to make it easier to use standard C functions, but
it hinders support for languages where the string type uses a length
instead of a special termination character.


1) The data for the databank "dbname" is stored in the subdirectory of
the same name.  This is done by using the dbname in the DBENV->open
call.

The database type is BTREE and not HASH.  From experience, the lookup
time is similar, the BTREE build time is faster than HASH, and the
file space needed for BTREE roughly a couple times larger than HASH.
The major advantage to BTREE is that it preserves the same semantics
at the flat-file index implementation, in that identifiers are
available in sorted order.

The need for this requirement is uncertain and a future specification
may change the default.  If that is the case, the format name will
change in the first line of the config.dat file.

2) The subdirectory contains a file named "config.dat" containing tab
separated key/value pairs.  The first line contains the key "index"
and value "index\tBerkeleyDB/1".  This means the first few characters
of the config.dat file is "index\tBerkeleyDB/1\n".

There is no other data in this file.

3) Global configuration data is stored in the database named "config".
At present there are only two entries in the config database:

   "primary_namespace" - contains the primary namespace name

   "secondary_namespaces" - contains the tab separated list of
      secondary namespaces.  If there are no secondary namespaces
      then this entry exists but contains the empty string as the
      value.

4) The "fileids" normalization table stored in the database named
"fileids".  The key is the fileid and the value is in the following format:

    <filename> "\t" <file length>

5) The mapping from primary identifier to location is stored in the
database named "key_${UNIQUE}" where ${UNIQUE} is the primary
identifier namespace.  For example, if the dbname is "swissprot" and
the primary namespace is named "ID" then the database name is
"key_ID".

6) The mappings from secondary namepaces to primary key are stored in
the database named "id_${NAMESPACE}".  For example, if there is a
namespace called "accession" which maps accession names to the primary
identifier then there is a database named "id_accession".

A mapping entry is stored with the key equal to the name in that
namespace and the value equal to the tab seperated primary identifier
names.  There must be at least one primary key in the list and if
there are N entries then there are N-1 tabs.

For example, the accession index for SWISS-PROT may be stored in the
environment "swissprot" under the database "id_accession" where the
key is "P02813" and the value is "PRP4_HUMAN\tPRPL_HUMAN\tPRPM_HUMAN".


  COMPRESSED FILES

The fastest indexing is done with uncompressed files, because record
retrieval can be done with seeking to the record start position and
reading the appropriate number of bytes.  Uncompressed files take up a
lot of space and the administrator may want to compress the files.

Reading from a compressed file is most easily done by using an
external program to generate an uncompressed output stream then
reading text up to the record beginning.  This is slower than seeking.
(NOTE: implementations are encouraged to use local library support for
a compression format, which may provide faster access to bytes in a
compressed file.)

The following requirements are optional, but if a user of the index
supports compression then it must be compatible with this section.

The known formats are "gzip", "compress" and "bzip2".  Use of those
formats is indicated by the filename extension.  The supported format
extensions are listed in the following table:

    Compression name    Extension
   -------------------------------
      gzip               gz, GZ
      compress           Z
      bzip2              bz2, BZ2

Uncompressed files must not have filenames with an ending listed in
this table.  The fileids table must store the filename including the
compression scheme.  The file length must be the length of the
compressed file.

This means if an administrator decides to compress or uncompress a
file then the fileids table must be updated to reflect that change.
This specification does not describe how to update the table.

(A clever implementation may decide to look for the compressed or
uncompressed file if the given filename is not found.  That cleverness
is outside the scope of this specification.)


    How to support versioning

A question came up during development of this specification asking how
to support versioning.  Some databanks may contain multiple versions
of the same record.  For example, the unversioned name may be "P1234"
and have two versions of the form "P1234.A" and "P1234.B".  In this
case, the unique identifier is the name with version while the
non-unique name is "P1234".  The database can be indexed based on the
primary key and with an alternate namepace used to store the
relationship between the non-versioned name and the available records.
